# DemandForge ğŸ”¨

**Comprehensive IT Demand Lifecycle Management Platform**

A production-ready Streamlit application for managing IT demands from ideation to closing. Built for Salling Group's retail operations to centralize documentation, stakeholder collaboration, and project artifacts across the entire demand lifecycle.

## ğŸ¯ Features

### Core Capabilities
- **9-Phase Demand Lifecycle**: Ideation â†’ Requirements â†’ Assessment â†’ Design â†’ Build â†’ Validation â†’ Deployment â†’ Implementation â†’ Closing
- **AI Co-Pilot**: Context-aware assistance for problem analysis, user stories, risk prediction, and test case generation
- **AI-Powered Test Case Generation**: Automatically generate manual and automated test cases from requirements and design â­ NEW
- **JIRA Test Integration**: Upload AI-generated test cases directly to JIRA with test plan management â­ NEW
- **AI Document Reading**: Extract text from PDFs, Word docs, Excel files, and web pages for AI context â­ NEW
- **Interactive Gantt Charts**: Visualize demand timeline with Plotly-based interactive charts â­ NEW
- **Stakeholder Management**: Track power/interest matrix, roles, and sign-offs
- **Progress Tracking**: Automatic calculation based on tab completion
- **Audit Logging**: Full change history with timestamps and trace IDs
- **Multi-Format Export**: JSON, Markdown, and PDF-ready HTML exports
- **Confluence Integration**: Document export capabilities
- **Session Management**: TTL-based with warning system
- **Security**: Input validation, HTML escaping, sanitization

### Tab-by-Tab Features

1. **ğŸ’¡ Ideation**: Problem statements, goals, background, constraints
2. **ğŸ“‹ Requirements**: Stakeholders, user stories, acceptance criteria, features
3. **ğŸ“Š Assessment**: Business case, ROI calculator, risks, dependencies
4. **ğŸ¨ Design**: Architecture, tech stack, data models, security
5. **ğŸ”¨ Build**: Task tracking, sprint planning, JIRA integration
6. **ğŸ§ª Validation**: Test cases, AI test generation, JIRA test upload, bug log, QA sign-off â­ ENHANCED
7. **ğŸš€ Deployment**: Rollout plans, environment config, training materials
8. **ğŸ“ˆ Implementation**: Metrics dashboard, issue tracking, user feedback
9. **ğŸ¯ Closing**: Retrospective, lessons learned, stakeholder sign-offs
10. **ğŸ“… Timeline**: Interactive Gantt charts with milestones and progress visualization â­ NEW

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10 or higher
- pip package manager

### Installation

1. **Clone or navigate to the repository**:
```powershell
cd c:\Users\248075\.vscode\cli\DemandForge
```

2. **Install dependencies**:
```powershell
pip install -r requirements.txt
```

3. **Configure environment (optional)**:
```powershell
cp .env.example .env
# Edit .env with your credentials (for real JIRA/Confluence integration)
```

4. **Run the application**:
```powershell
streamlit run app.py
```

5. **Open your browser** to `http://localhost:8501`

## ğŸ“ Project Structure

```
DemandForge/
â”œâ”€â”€ app.py                      # Main Streamlit application (2,000+ lines)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ JIRA_INTEGRATION_GUIDE.md  # JIRA test case integration guide â­ NEW
â”œâ”€â”€ JIRA_IMPLEMENTATION_SUMMARY.md  # Technical implementation details â­ NEW
â”œâ”€â”€ JIRA_ARCHITECTURE.md       # Architecture diagrams â­ NEW
â”œâ”€â”€ OPTION4_COMPLETE.md        # AI document reading & Gantt features â­ NEW
â”œâ”€â”€ TEST_GUIDE.md              # Testing instructions â­ NEW
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ demand.py              # Pydantic models for all tabs
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py          # Abstract agent interface
â”‚   â”œâ”€â”€ mock_agent.py          # Mock AI agent implementation
â”‚   â””â”€â”€ gemini_agent.py        # Gemini 2.5 Flash integration â­ NEW
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ jira_client.py         # JIRA API integration (Build phase)
â”‚   â”œâ”€â”€ jira_test_client.py    # JIRA test case integration â­ NEW
â”‚   â””â”€â”€ confluence_client.py   # Confluence API integration
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ jira_test_ui.py        # JIRA test UI components â­ NEW
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ progress.py            # Progress calculation
â”‚   â”œâ”€â”€ export.py              # Export to JSON/Markdown/PDF
â”‚   â”œâ”€â”€ validation.py          # Security and validation
â”‚   â”œâ”€â”€ logging_config.py      # Structured logging
â”‚   â”œâ”€â”€ storage.py             # JSON file storage
â”‚   â”œâ”€â”€ document_reader.py     # AI document reading â­ NEW
â”‚   â””â”€â”€ gantt_chart.py         # Interactive Gantt charts â­ NEW
â”œâ”€â”€ data/                      # Demand storage (JSON files)
â”‚   â”œâ”€â”€ demands_index.json     # Fast lookup index
â”‚   â””â”€â”€ demands/               # Individual demand files
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_agent.py          # Agent tests
    â”œâ”€â”€ test_validation.py     # Validation tests
    â”œâ”€â”€ test_progress.py       # Progress calculation tests
    â””â”€â”€ test_jira.py           # JIRA integration tests
```

## ğŸ§ª Testing

Run the full test suite:

```powershell
pytest tests/ -v
```

Run specific test file:

```powershell
pytest tests/test_agent.py -v
```

Run with coverage:

```powershell
pytest --cov=. --cov-report=html tests/
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file from `.env.example`:

```env
# JIRA Configuration
JIRA_URL=https://your-company.atlassian.net
JIRA_EMAIL=your-email@company.com
JIRA_API_TOKEN=your_token_here

# Confluence Configuration
CONFLUENCE_URL=https://your-company.atlassian.net/wiki
CONFLUENCE_API_TOKEN=your_token_here

# Session Configuration
SESSION_TTL_MINUTES=60

# Role-Based Access (Future)
ENABLE_ROLE_CHECK=false
```

### Real JIRA/Confluence Integration

To enable real API calls (instead of mocks):

1. Set up API tokens in Atlassian
2. Configure `.env` with your credentials
3. Update `app.py` to use `RealJiraClient` and `RealConfluenceClient`

## ğŸ’¡ Usage Guide

### Creating a New Demand

1. **Launch the app** - A unique demand ID is auto-generated (e.g., LOG-2025-A1B2C3D4)
2. **Use the AI Co-Pilot** - Ask questions, generate content, get suggestions
3. **Fill tabs sequentially** - Data flows forward (e.g., goals â†’ features)
4. **Track progress** - Progress bar updates automatically
5. **Export anytime** - JSON for data, Markdown for reports

### ğŸ¤– AI Test Case Generation (NEW!)

**Automatically generate and upload test cases to JIRA:**

1. **Setup JIRA Connection** (one-time):
   - Go to Validation tab
   - Expand "ğŸ”— JIRA Connection Setup"
   - Get your API token from https://id.atlassian.com/manage-profile/security/api-tokens
   - Enter JIRA URL, email, token, and project key
   - Click "Save & Test Connection"

2. **Generate Manual Test Cases**:
   - Fill in Requirements tab first (user stories, acceptance criteria)
   - Go to Validation â†’ "ğŸ“ Manual Test Cases"
   - Set number of test cases (1-20)
   - Choose default priority
   - Click "ğŸ¤– Generate Manual Test Cases"
   - Review and edit generated tests
   - Click "ğŸ“¤ Upload All to JIRA"

3. **Generate Automated Test Cases**:
   - Fill in Design tab first (architecture, tech stack)
   - Go to Validation â†’ "âš™ï¸ Automated Test Cases"
   - Choose test framework (pytest, selenium, etc.)
   - Set number of test cases (1-30)
   - Click "ğŸ¤– Generate Automated Test Cases"
   - Review test code snippets
   - Click "ğŸ“¤ Upload All to JIRA"

4. **Create Test Plan**:
   - Generate test cases first (manual and/or automated)
   - Scroll to "ğŸ“‹ Test Plan Generator"
   - Enter test plan name and description
   - Enable "Generate AI Test Strategy" for comprehensive plan
   - Click "ğŸ“‹ Create Test Plan in JIRA"
   - Test plan is created as an Epic in JIRA

**See [JIRA_INTEGRATION_GUIDE.md](JIRA_INTEGRATION_GUIDE.md) for detailed instructions.**

### ğŸ“„ AI Document Reading (NEW!)

**Extract text from documents for AI context:**

- **Supported formats**: PDF, Word (.docx), Excel (.xlsx), Images (metadata), URLs
- **How to use**:
  1. Go to any phase tab (Requirements, Design, etc.)
  2. Scroll to "Attachments" section
  3. Upload files or add URLs
  4. Files are automatically read when using AI assistant
  5. Click "Ask AI about attachments" for document-specific questions

**Examples:**
- Upload requirements PDF â†’ AI generates test cases from it
- Add API documentation URL â†’ AI generates automated tests
- Upload design diagrams â†’ AI analyzes architecture

### ğŸ“… Interactive Timeline (NEW!)

**Visualize your demand timeline:**

1. Go to **Timeline** tab (new 10th tab)
2. View three visualization types:
   - **Timeline View**: Gantt chart with all 9 phases
   - **Milestones View**: Key deliverables with diamond markers
   - **Progress View**: Horizontal bar chart of completion %
3. Customize:
   - Set project start date
   - Adjust phase durations
   - Add custom milestones
4. Export timeline as image or interactive HTML

### AI Co-Pilot Commands

The AI assistant responds to:
- "Analyze the problem" â†’ 5 Whys analysis
- "Generate user stories" â†’ INVEST-format stories
- "What are the risks?" â†’ RAG-based risk analysis
- "Create test cases" â†’ Test scenarios from requirements
- "Suggest architecture" â†’ Design patterns and best practices
- "Help with estimation" â†’ Effort and cost guidance
- "Summarize this document" â†’ Extract key points from attachments
- "Generate automated tests" â†’ Code-based test cases

### Best Practices

1. **Start with Ideation**: Clearly define the problem before moving forward
2. **Add Stakeholders Early**: Identify all affected parties in Requirements
3. **Quantify Everything**: Use specific metrics for goals and ROI
4. **Link Phases**: Reference earlier tabs (e.g., link tests to acceptance criteria)
5. **Save Frequently**: Each tab has a save button - use it
6. **Export for Backup**: Download JSON periodically
7. **Complete Closing**: Capture lessons learned while fresh

## ğŸ”’ Security Features

- **Input Validation**: Pydantic models with max lengths
- **Output Escaping**: HTML sanitization for all user content
- **Session TTL**: Automatic timeout after 60 minutes
- **Audit Logging**: All changes tracked with trace IDs
- **PII Protection**: Structured logger redacts sensitive fields
- **Path Sanitization**: Filename validation prevents traversal

## ğŸš€ Deployment

### Local Development
```powershell
streamlit run app.py
```

### Production (Streamlit Cloud)
1. Push to GitHub
2. Connect repository in Streamlit Cloud
3. Add secrets (JIRA tokens, etc.)
4. Deploy

### Docker (Future)
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["streamlit", "run", "app.py"]
```

## ğŸ“ˆ Roadmap

### Phase 1 (Current - POC)
- âœ… All 9 tabs with full functionality
- âœ… Mock AI agent
- âœ… Session state persistence
- âœ… Mock JIRA/Confluence integration
- âœ… Export to JSON/Markdown

### Phase 2 (Next)
- [ ] PostgreSQL persistence
- [ ] Real Watsonx AI integration
- [ ] RAG from historical demands
- [ ] Real-time collaboration (WebSockets)
- [ ] Role-based access control

### Phase 3 (Future)
- [ ] API for cross-app integration
- [ ] Webhook triggers
- [ ] Mobile app
- [ ] Advanced analytics dashboard
- [ ] ML-powered recommendations

## ğŸ¤ Contributing

### Development Setup

1. **Create virtual environment**:
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

2. **Install dev dependencies**:
```powershell
pip install -r requirements.txt
pip install pytest pytest-cov black flake8 mypy
```

3. **Run code formatters**:
```powershell
black . --line-length 100
flake8 . --max-line-length=100
mypy . --ignore-missing-imports
```

### Code Style

- **PEP 8** compliance
- **Type hints** on all functions
- **Docstrings** (Google style)
- **Max line length**: 100 characters
- **Imports**: stdlib â†’ third-party â†’ local

## ğŸ“„ License

Â© 2025 Salling Group. Internal use only.

## ğŸ†˜ Support

### Common Issues

**Q: "Import errors when running app"**  
A: Install dependencies: `pip install -r requirements.txt`

**Q: "Session expires too quickly"**  
A: Adjust `SESSION_TTL_MINUTES` in `.env` (default: 60)

**Q: "AI responses are generic"**  
A: Fill more tabs to provide context. The AI uses all available data.

**Q: "JIRA integration doesn't work"**  
A: Currently using mock mode. Configure `.env` for real integration.

### Contact

- **Technical Lead**: [Your Name]
- **Project**: DemandForge
- **Organization**: Salling Group IT

## ğŸ“ Tutorial

### Example: Complete Demand Flow

```python
# 1. IDEATION
Problem: "Manual promotion setup takes 4 hours per campaign"
Goals: "Automate 80% of promo setup, reduce time to 30 minutes"

# 2. REQUIREMENTS  
Stakeholders: [Marketing Manager, IT Lead, Store Ops]
User Stories: "As a Marketing Manager, I want to clone previous promos..."

# 3. ASSESSMENT
ROI: 45% (â‚¬150K investment â†’ â‚¬217K return)
Risks: "Integration with legacy promo system may cause delays"

# 4. DESIGN
Architecture: "REST API â†’ Azure Functions â†’ SQL Database"
Stack: "Python 3.10, FastAPI, Azure, Postgres"

# 5. BUILD
Tasks: ["API endpoints", "DB migrations", "UI components"]
JIRA: Create Epic LOG-1234

# 6. VALIDATION
Tests: 45 test cases, 87% coverage
QA: âœ… Signed off

# 7. DEPLOYMENT
Date: 2025-11-01
Rollout: "Pilot with 10 stores, then full rollout"

# 8. IMPLEMENTATION
Metrics: Uptime 99.7%, Adoption 82%, Time saved: 3.5 hrs/campaign

# 9. CLOSING
Retrospective: "Great collaboration. Need better test data next time."
Sign-offs: âœ… All stakeholders approved
```

---

**Built with â¤ï¸ using Streamlit, Python, and AI**

*DemandForge v1.0 - October 2025*
